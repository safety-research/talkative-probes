#!/bin/sh
# This script was created by sbatch --wrap.

bash -c 'cd /workspace/kitf/talkative-probes/consistency-lens && source scripts/ensure_env.sh && ulimit -n 65536 && uv_run torchrun --nproc_per_node=8 --master_port=29817 scripts/01_train_distributed.py --config-path=/workspace/kitf/talkative-probes/consistency-lens/conf --config-name=gemma3_27b_frozen_nopostfix wandb_resume_id="false" run_suffix="frozenenc_add_patch" num_train_epochs=2 t_text=4 batch_size=8 group_n=4 trainable_components.encoder.output_layer=45 gradient_accumulation_steps=1 grad_clip=0.05 lm_base_weight=0 mse_weight=0.00001 GRPO_weight=1.0 kl_base_weight=0 learning_rate=1e-3 weight_decay=0.00001 trainable_components.decoder.use_kv_cache=true lr_scheduler.warmup_steps=100 custom_lr_multipliers.overall_encoder=0.1 trainable_components.encoder.add_current_token=true trainable_components.decoder.projection_init_method=default entropy_weight=1 verbose_samples.num_samples=5 verbose_samples.interval=3000 dataset.on_the_fly.enabled=true dataset.on_the_fly.samples_per_regeneration_cycle=10000 dataset.on_the_fly.max_val_samples=50000 trainable_components.decoder.patch_all_layers=5 resume_reset_steps=true grad_clip_enc=1 entropy_clamp_schedule.num_steps=10000os dataset.on_the_fly.generation_batch_size=8'
