# Configuration for SimpleStories Frozen Base Model Experiment
# This config trains consistency lens on SimpleStories-5M with the base model frozen throughout

# Inherit all settings from config.yaml
defaults:
  - config
  - _self_

layer_l: 4
# Override specific settings for this experiment
t_text: 4                     # Width-10 explanations as requested
batch_size: 3072 

alpha_schedule:
    value: 0.1

learning_rate: 1.0e-3

num_train_epochs: 10

gumbel_tau_schedule:
  type: "linear_decay_after_constant"  # Options: constant, linear_decay, cosine_anneal, exponential_decay, linear_decay_after_constant
  constant_steps_before_decay: "2e"  # Duration of constant phase - Examples: "5000s", "2e", "10000steps", "5epochs"
  start_value: 1.0
  end_value: 0.1
  num_steps: "-1" 


# Ensure base model stays frozen
trainable_components:
  decoder:
    base_model: false                 # FROZEN throughout
    projection_layer: true
    eye_init: true
    output_head: false                # Keep LM head frozen too
  encoder:
    base_model: false                 # FROZEN throughout
    use_base_model: true
    projection_layer: true
    eye_init: true
    output_layer: 4

# No freeze schedule needed
freeze_schedule:
  enabled: false

# WandB configuration
wandb:
  project: "consistency-lens-simplestories"
  mode: "online"