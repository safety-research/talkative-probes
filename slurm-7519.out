[ensure_env] Using cached venv: /home/kitf/.cache/uv/envs/consistency-lens
[ensure_env] Installing Python 3.12 via uv...
[ensure_env] Environment already exists at /home/kitf/.cache/uv/envs/consistency-lens
[ensure_env] Running on SLURM node: node-1
[ensure_env] Environment ready. Use 'uv run' (not uv_run) for all Python commands.
[ensure_env] Note: The uv_run function is available as a shortcut in this shell.
[ensure_env] Linked .venv -> /home/kitf/.cache/uv/envs/consistency-lens
Resolved 163 packages in 3.61s
Uninstalled 19 packages in 25.31s
warning: Failed to hardlink files; falling back to full copy. This may lead to degraded performance.
         If the cache and target directories are on different filesystems, hardlinking may not be supported.
         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.
Installed 19 packages in 1m 35s
 - numpy==2.3.2
 + numpy==2.2.6
 - nvidia-cublas-cu12==12.6.4.1
 + nvidia-cublas-cu12==12.8.4.1
 - nvidia-cuda-cupti-cu12==12.6.80
 + nvidia-cuda-cupti-cu12==12.8.90
 - nvidia-cuda-nvrtc-cu12==12.6.77
 + nvidia-cuda-nvrtc-cu12==12.8.93
 - nvidia-cuda-runtime-cu12==12.6.77
 + nvidia-cuda-runtime-cu12==12.8.90
 - nvidia-cudnn-cu12==9.5.1.17
 + nvidia-cudnn-cu12==9.10.2.21
 - nvidia-cufft-cu12==11.3.0.4
 + nvidia-cufft-cu12==11.3.3.83
 - nvidia-cufile-cu12==1.11.1.6
 + nvidia-cufile-cu12==1.13.1.3
 - nvidia-curand-cu12==10.3.7.77
 + nvidia-curand-cu12==10.3.9.90
 - nvidia-cusolver-cu12==11.7.1.2
 + nvidia-cusolver-cu12==11.7.3.90
 - nvidia-cusparse-cu12==12.5.4.2
 + nvidia-cusparse-cu12==12.5.8.93
 - nvidia-cusparselt-cu12==0.6.3
 + nvidia-cusparselt-cu12==0.7.1
 - nvidia-nccl-cu12==2.26.2
 + nvidia-nccl-cu12==2.27.5
 - nvidia-nvjitlink-cu12==12.6.85
 + nvidia-nvjitlink-cu12==12.8.93
 - nvidia-nvtx-cu12==12.6.77
 + nvidia-nvtx-cu12==12.8.90
 - setuptools==80.9.0
 + setuptools==79.0.1
 - torch==2.7.1
 + torch==2.9.0.dev20250804+cu128
 - torchvision==0.22.1
 + torchvision==0.24.0.dev20250804+cu128
 - triton==3.3.1
 + triton==3.4.0+git663e04e8
Waiting for vLLM server... (1)
Ignoring existing lockfile due to change in pre-release mode: `allow` vs. `if-necessary-or-explicit`
  × No solution found when resolving dependencies:
  ╰─▶ Because vllm==0.10.1+gptoss depends on torch==2.9.0.dev20250804+cu128
      and there is no version of torch==2.9.0.dev20250804+cu128, we can
      conclude that vllm==0.10.1+gptoss cannot be used.
      And because your project depends on vllm==0.10.1+gptoss, we can conclude
      that your project's requirements are unsatisfiable.

      hint: `torch` was requested with a pre-release marker (e.g.,
      torch==2.9.0.dev20250804+cu128), but pre-releases weren't enabled (try:
      `--prerelease=allow`)

      hint: `torch` was found on https://pypi.org/simple, but not
      at the requested version (torch==2.9.0.dev20250804+cu128). A
      compatible version may be available on a subsequent index (e.g.,
      https://download.pytorch.org/whl/nightly/cu128). By default, uv will
      only consider versions that are published on the first index that
      contains a given package, to avoid dependency confusion attacks. If all
      indexes are equally trusted, use `--index-strategy unsafe-best-match` to
      consider all versions from all indexes, regardless of the order in which
      they were defined.
Waiting for vLLM server... (2)
Waiting for vLLM server... (3)
Waiting for vLLM server... (4)
Waiting for vLLM server... (5)
Waiting for vLLM server... (6)
Waiting for vLLM server... (7)
Waiting for vLLM server... (8)
Waiting for vLLM server... (9)
Waiting for vLLM server... (10)
Waiting for vLLM server... (11)
Waiting for vLLM server... (12)
Waiting for vLLM server... (13)
Waiting for vLLM server... (14)
Waiting for vLLM server... (15)
Waiting for vLLM server... (16)
Waiting for vLLM server... (17)
Waiting for vLLM server... (18)
Waiting for vLLM server... (19)
Waiting for vLLM server... (20)
Waiting for vLLM server... (21)
Waiting for vLLM server... (22)
Waiting for vLLM server... (23)
Waiting for vLLM server... (24)
Waiting for vLLM server... (25)
Waiting for vLLM server... (26)
Waiting for vLLM server... (27)
Waiting for vLLM server... (28)
Waiting for vLLM server... (29)
Waiting for vLLM server... (30)
Waiting for vLLM server... (31)
Waiting for vLLM server... (32)
Waiting for vLLM server... (33)
Waiting for vLLM server... (34)
Waiting for vLLM server... (35)
Waiting for vLLM server... (36)
Waiting for vLLM server... (37)
Waiting for vLLM server... (38)
Waiting for vLLM server... (39)
Waiting for vLLM server... (40)
Waiting for vLLM server... (41)
Waiting for vLLM server... (42)
Waiting for vLLM server... (43)
Waiting for vLLM server... (44)
Waiting for vLLM server... (45)
Waiting for vLLM server... (46)
Waiting for vLLM server... (47)
Waiting for vLLM server... (48)
Waiting for vLLM server... (49)
Waiting for vLLM server... (50)
Waiting for vLLM server... (51)
Waiting for vLLM server... (52)
Waiting for vLLM server... (53)
Waiting for vLLM server... (54)
Waiting for vLLM server... (55)
Waiting for vLLM server... (56)
Waiting for vLLM server... (57)
Waiting for vLLM server... (58)
Waiting for vLLM server... (59)
Waiting for vLLM server... (60)
Ignoring existing lockfile due to change in pre-release mode: `allow` vs. `if-necessary-or-explicit`
  × No solution found when resolving dependencies:
  ╰─▶ Because vllm==0.10.1+gptoss depends on torch==2.9.0.dev20250804+cu128
      and there is no version of torch==2.9.0.dev20250804+cu128, we can
      conclude that vllm==0.10.1+gptoss cannot be used.
      And because your project depends on vllm==0.10.1+gptoss, we can conclude
      that your project's requirements are unsatisfiable.

      hint: `torch` was requested with a pre-release marker (e.g.,
      torch==2.9.0.dev20250804+cu128), but pre-releases weren't enabled (try:
      `--prerelease=allow`)

      hint: `torch` was found on https://pypi.org/simple, but not
      at the requested version (torch==2.9.0.dev20250804+cu128). A
      compatible version may be available on a subsequent index (e.g.,
      https://download.pytorch.org/whl/nightly/cu128). By default, uv will
      only consider versions that are published on the first index that
      contains a given package, to avoid dependency confusion attacks. If all
      indexes are equally trusted, use `--index-strategy unsafe-best-match` to
      consider all versions from all indexes, regardless of the order in which
      they were defined.
