[ensure_env] Using cached venv: /home/kitf/.cache/uv/envs/consistency-lens
[ensure_env] Installing Python 3.12 via uv...
[ensure_env] Environment already exists at /home/kitf/.cache/uv/envs/consistency-lens
Ignoring existing lockfile due to change in pre-release mode: `if-necessary-or-explicit` vs. `allow`
Resolved 224 packages in 26.89s
Removed antlr4-python3-runtime v4.9.3
Updated cffi v1.17.1 -> v2.0.0b1
Updated defusedxml v0.7.1 -> v0.8.0rc2
Updated fastjsonschema v2.21.1 -> v2.21.2
Updated filelock v3.18.0 -> v3.19.1
Updated fonttools v4.59.0 -> v4.59.1
Updated hf-xet v1.1.7 -> v1.1.8rc0
Updated huggingface-hub v0.34.4 -> v0.35.0rc0
Updated hydra-core v1.3.2 -> v1.4.0.dev1
Added importlib-metadata v8.7.0
Added intel-cmplr-lib-ur v2025.1.1
Added intel-openmp v2025.1.1
Updated ipykernel v6.30.1 -> v7.0.0a2
Updated jupyterlab v4.4.5 -> v4.5.0a3
Updated kiwisolver v1.4.9 -> v1.4.10rc0
Updated narwhals v2.1.1 -> v2.1.2
Updated notebook v7.4.5 -> v7.5.0a1
Updated numpy v2.2.6 -> v2.3.2
Updated nvidia-nccl-cu12 v2.27.3 -> v2.27.5
Added nvidia-nvshmem-cu12 v3.3.20
Updated omegaconf v2.3.0 -> v2.4.0.dev3
Added opentelemetry-api v1.36.0
Added opentelemetry-sdk v1.36.0
Added opentelemetry-semantic-conventions v0.57b0
Updated protobuf v6.31.1 -> v6.32.0
Updated pydantic v2.11.7 -> v2.12.0a1
Updated pydantic-core v2.33.2 -> v2.37.2
Updated python-json-logger v3.3.0 -> v4.0.0.dev0
Added pytorch-triton v3.4.0+gitf7888497
Updated sentry-sdk v2.34.1 -> v3.0.0a5
Updated setuptools v79.0.1 -> v80.9.0
Added tcmlib v1.3.0
Updated torch v2.8.0 -> v2.9.0.dev20250817+cu128
Updated torchdata v0.11.0 -> v0.12.0.dev20250220
Added umf v0.10.0
Added zipp v3.23.0
Resolved 224 packages in 19ms
   Building talkative-autoencoders @ file:///workspace/kitf/talkative-probes/talkative_autoencoder
Downloading pytorch-triton (147.5MiB)
Downloading fonttools (4.7MiB)
Downloading hf-xet (3.0MiB)
Downloading pydantic-core (1.9MiB)
Downloading nvidia-nvshmem-cu12 (118.9MiB)
Downloading notebook (13.6MiB)
Downloading jupyterlab (11.8MiB)
Downloading kiwisolver (1.4MiB)
Downloading torch (858.0MiB)
   Building triton-kernels @ git+https://github.com/triton-lang/triton.git@4d6d47d6f3ec27113e746b4b9ded393066ce3273#subdirectory=python/triton_kernels
 Downloading kiwisolver
 Downloading pydantic-core
 Downloading hf-xet
      Built talkative-autoencoders @ file:///workspace/kitf/talkative-probes/talkative_autoencoder
      Built triton-kernels @ git+https://github.com/triton-lang/triton.git@4d6d47d6f3ec27113e746b4b9ded393066ce3273#subdirectory=python/triton_kernels
 Downloading fonttools
 Downloading nvidia-nvshmem-cu12
 Downloading pytorch-triton
 Downloading notebook
 Downloading jupyterlab
 Downloading torch
Prepared 28 packages in 3m 59s
Uninstalled 95 packages in 1.93s
warning: Failed to hardlink files; falling back to full copy. This may lead to degraded performance.
         If the cache and target directories are on different filesystems, hardlinking may not be supported.
         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.
Installed 32 packages in 1m 16s
 - antlr4-python3-runtime==4.9.3
 - astor==0.8.1
 - blake3==1.0.5
 - cachetools==6.1.0
 - cbor2==5.7.0
 - cffi==1.17.1
 + cffi==2.0.0b1
 - chz==0.3.0
 - cloudpickle==3.1.1
 - compressed-tensors==0.10.2
 - cuda-bindings==13.0.0
 - cuda-pathfinder==1.1.0
 - cuda-python==13.0.0
 - cupy-cuda12x==13.5.1
 - defusedxml==0.7.1
 + defusedxml==0.8.0rc2
 - depyf==0.19.0
 - diskcache==5.6.3
 - distro==1.9.0
 - dnspython==2.7.0
 - docker==7.1.0
 - email-validator==2.2.0
 - fastapi-cli==0.0.8
 - fastapi-cloud-cli==0.1.5
 - fastjsonschema==2.21.1
 + fastjsonschema==2.21.2
 - fastrlock==0.8.3
 - filelock==3.18.0
 + filelock==3.19.1
 - flashinfer-python==0.2.8
 - fonttools==4.59.0
 + fonttools==4.59.1
 - gguf==0.17.1
 - gpt-oss==0.1.0
 - hf-xet==1.1.7
 + hf-xet==1.1.8rc0
 - html2text==2025.4.15
 - httpx-sse==0.4.1
 - huggingface-hub==0.34.4
 + huggingface-hub==0.35.0rc0
 - hydra-core==1.3.2
 + hydra-core==1.4.0.dev1
 + importlib-metadata==8.7.0
 - interegular==0.3.3
 - ipykernel==6.30.1
 + ipykernel==7.0.0a2
 - jiter==0.10.0
 - jupyterlab==4.4.5
 + jupyterlab==4.5.0a3
 - kiwisolver==1.4.9
 + kiwisolver==1.4.10rc0
 - llguidance==0.7.30
 - llvmlite==0.44.0
 - lm-format-enforcer==0.10.12
 - lxml==6.0.0
 - markdown-it-py==4.0.0
 - mcp==1.12.4
 - mdurl==0.1.2
 - mistral-common==1.8.3
 - msgspec==0.19.0
 - narwhals==2.1.1
 + narwhals==2.1.2
 - notebook==7.4.5
 + notebook==7.5.0a1
 - numba==0.61.2
 - numpy==2.2.6
 + numpy==2.3.2
 - nvidia-cudnn-frontend==1.14.0
 - nvidia-nvshmem-cu12==3.3.9
 + nvidia-nvshmem-cu12==3.3.20
 - omegaconf==2.3.0
 + omegaconf==2.4.0.dev3
 - openai==1.99.9
 - openai-harmony==0.0.4
 - opencv-python-headless==4.12.0.88
 + opentelemetry-api==1.36.0
 + opentelemetry-sdk==1.36.0
 + opentelemetry-semantic-conventions==0.57b0
 - outlines-core==0.2.10
 - partial-json-parser==0.2.1.1.post6
 - prometheus-fastapi-instrumentator==7.1.0
 - protobuf==6.31.1
 + protobuf==6.32.0
 - pybase64==1.4.2
 - pycountry==24.6.1
 - pydantic==2.11.7
 + pydantic==2.12.0a1
 - pydantic-core==2.33.2
 + pydantic-core==2.37.2
 - pydantic-extra-types==2.10.5
 - pydantic-settings==2.10.1
 - pynvml==11.5.3
 - python-json-logger==3.3.0
 + python-json-logger==4.0.0.dev0
 - python-multipart==0.0.20
 - pytorch-triton==3.4.0+git11ec6354
 + pytorch-triton==3.4.0+gitf7888497
 - ray==2.48.0
 - rich==14.1.0
 - rich-toolkit==0.15.0
 - rignore==0.6.4
 - sentry-sdk==2.34.1
 + sentry-sdk==3.0.0a5
 - setproctitle==1.3.6
 - setuptools==79.0.1
 + setuptools==80.9.0
 - shellingham==1.5.4
 - soundfile==0.13.1
 - soxr==0.5.0.post1
 - sse-starlette==3.0.2
 - structlog==25.4.0
 ~ talkative-autoencoders==0.1.0 (from file:///workspace/kitf/talkative-probes/talkative_autoencoder)
 - tenacity==9.1.2
 - termcolor==3.1.0
 - torch==2.9.0.dev20250804+cu128
 + torch==2.9.0.dev20250817+cu128
 - torchaudio==2.8.0.dev20250804+cu128
 - torchdata==0.11.0
 + torchdata==0.12.0.dev20250220
 - torchvision==0.24.0.dev20250804+cu128
 - triton-kernels==1.0.0
 + triton-kernels==1.0.0 (from git+https://github.com/triton-lang/triton.git@4d6d47d6f3ec27113e746b4b9ded393066ce3273#subdirectory=python/triton_kernels)
 - typer==0.16.0
 - vllm==0.10.1+gptoss
 - xgrammar==0.1.21
 + zipp==3.23.0
[ensure_env] Running on SLURM node: node-0
[ensure_env] Environment ready. Use 'uv run' (not uv_run) for all Python commands.
[ensure_env] Note: The uv_run function is available as a shortcut in this shell.
[ensure_env] Linked .venv -> /home/kitf/.cache/uv/envs/consistency-lens
Resolved 224 packages in 18ms
Audited 216 packages in 11ms
/home/kitf/.cache/uv/envs/consistency-lens/bin/python: No module named pip
/var/lib/slurm-llnl/slurmd/job07547/slurm_script: line 21: /home/kitf/.cache/uv/envs/consistency-lens/bin/vllm: No such file or directory
Waiting for vLLM server... (1)
Waiting for vLLM server... (2)
Waiting for vLLM server... (3)
Waiting for vLLM server... (4)
Waiting for vLLM server... (5)
Waiting for vLLM server... (6)
Waiting for vLLM server... (7)
Waiting for vLLM server... (8)
Waiting for vLLM server... (9)
Waiting for vLLM server... (10)
Waiting for vLLM server... (11)
Waiting for vLLM server... (12)
Waiting for vLLM server... (13)
Waiting for vLLM server... (14)
Waiting for vLLM server... (15)
Waiting for vLLM server... (16)
Waiting for vLLM server... (17)
Waiting for vLLM server... (18)
Waiting for vLLM server... (19)
Waiting for vLLM server... (20)
Waiting for vLLM server... (21)
Waiting for vLLM server... (22)
Waiting for vLLM server... (23)
Waiting for vLLM server... (24)
Waiting for vLLM server... (25)
Waiting for vLLM server... (26)
Waiting for vLLM server... (27)
Waiting for vLLM server... (28)
Waiting for vLLM server... (29)
Waiting for vLLM server... (30)
Waiting for vLLM server... (31)
Waiting for vLLM server... (32)
Waiting for vLLM server... (33)
Waiting for vLLM server... (34)
Waiting for vLLM server... (35)
Waiting for vLLM server... (36)
Waiting for vLLM server... (37)
Waiting for vLLM server... (38)
Waiting for vLLM server... (39)
Waiting for vLLM server... (40)
Waiting for vLLM server... (41)
Waiting for vLLM server... (42)
Waiting for vLLM server... (43)
Waiting for vLLM server... (44)
Waiting for vLLM server... (45)
Waiting for vLLM server... (46)
Waiting for vLLM server... (47)
Waiting for vLLM server... (48)
Waiting for vLLM server... (49)
Waiting for vLLM server... (50)
Waiting for vLLM server... (51)
Waiting for vLLM server... (52)
Waiting for vLLM server... (53)
Waiting for vLLM server... (54)
Waiting for vLLM server... (55)
Waiting for vLLM server... (56)
Waiting for vLLM server... (57)
Waiting for vLLM server... (58)
Waiting for vLLM server... (59)
Waiting for vLLM server... (60)
Waiting for vLLM server... (61)
Waiting for vLLM server... (62)
Waiting for vLLM server... (63)
Waiting for vLLM server... (64)
Waiting for vLLM server... (65)
Waiting for vLLM server... (66)
Waiting for vLLM server... (67)
Waiting for vLLM server... (68)
Waiting for vLLM server... (69)
Waiting for vLLM server... (70)
Waiting for vLLM server... (71)
Waiting for vLLM server... (72)
Waiting for vLLM server... (73)
Waiting for vLLM server... (74)
Waiting for vLLM server... (75)
Waiting for vLLM server... (76)
Waiting for vLLM server... (77)
Waiting for vLLM server... (78)
Waiting for vLLM server... (79)
Waiting for vLLM server... (80)
Waiting for vLLM server... (81)
Waiting for vLLM server... (82)
Waiting for vLLM server... (83)
Waiting for vLLM server... (84)
Waiting for vLLM server... (85)
Waiting for vLLM server... (86)
Waiting for vLLM server... (87)
Waiting for vLLM server... (88)
Waiting for vLLM server... (89)
Waiting for vLLM server... (90)
Waiting for vLLM server... (91)
Waiting for vLLM server... (92)
Waiting for vLLM server... (93)
Waiting for vLLM server... (94)
Waiting for vLLM server... (95)
Waiting for vLLM server... (96)
Waiting for vLLM server... (97)
Waiting for vLLM server... (98)
Waiting for vLLM server... (99)
Waiting for vLLM server... (100)
Waiting for vLLM server... (101)
Waiting for vLLM server... (102)
Waiting for vLLM server... (103)
Waiting for vLLM server... (104)
Waiting for vLLM server... (105)
Waiting for vLLM server... (106)
Waiting for vLLM server... (107)
Waiting for vLLM server... (108)
Waiting for vLLM server... (109)
Waiting for vLLM server... (110)
Waiting for vLLM server... (111)
Waiting for vLLM server... (112)
Waiting for vLLM server... (113)
Waiting for vLLM server... (114)
Waiting for vLLM server... (115)
Waiting for vLLM server... (116)
Waiting for vLLM server... (117)
Waiting for vLLM server... (118)
Waiting for vLLM server... (119)
Waiting for vLLM server... (120)
/home/kitf/.cache/uv/envs/consistency-lens/bin/python: Error while finding module specification for 'talkative_autoencoder.scripts.generate_thinking_dataset' (ModuleNotFoundError: No module named 'talkative_autoencoder')
