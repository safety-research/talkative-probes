[ensure_env] Using cached venv: /home/kitf/.cache/uv/envs/consistency-lens
[ensure_env] Installing Python 3.12 via uv...
[ensure_env] Environment already exists at /home/kitf/.cache/uv/envs/consistency-lens
Resolved 224 packages in 18ms
Resolved 224 packages in 28ms
Audited 216 packages in 11ms
[ensure_env] Running on SLURM node: node-0
[ensure_env] Environment ready. Use 'uv run' (not uv_run) for all Python commands.
[ensure_env] Note: The uv_run function is available as a shortcut in this shell.
[ensure_env] Linked .venv -> /home/kitf/.cache/uv/envs/consistency-lens
Resolved 224 packages in 20ms
Audited 216 packages in 10ms
Resolved 169 packages in 6.20s
Downloading lxml (5.0MiB)
 Downloading lxml
Prepared 3 packages in 3.16s
Uninstalled 6 packages in 25.68s
warning: Failed to hardlink files; falling back to full copy. This may lead to degraded performance.
         If the cache and target directories are on different filesystems, hardlinking may not be supported.
         If this is intentional, set `export UV_LINK_MODE=copy` or use `--link-mode=copy` to suppress this warning.
Installed 73 packages in 1m 50s
 + astor==0.8.1
 + blake3==1.0.5
 + cachetools==6.1.0
 + cbor2==5.7.0
 + chz==0.3.0
 + cloudpickle==3.1.1
 + compressed-tensors==0.10.2
 + cuda-bindings==13.0.0
 + cuda-pathfinder==1.1.0
 + cuda-python==13.0.0
 + cupy-cuda12x==13.5.1
 + depyf==0.19.0
 + diskcache==5.6.3
 + distro==1.9.0
 + dnspython==2.7.0
 + docker==7.1.0
 + email-validator==2.2.0
 + fastapi-cli==0.0.8
 + fastapi-cloud-cli==0.1.5
 + fastrlock==0.8.3
 + flashinfer-python==0.2.8
 + gguf==0.17.1
 + gpt-oss==0.1.0
 + html2text==2025.4.15
 + httpx-sse==0.4.1
 + interegular==0.3.3
 + jiter==0.10.0
 + llguidance==0.7.30
 + llvmlite==0.44.0
 + lm-format-enforcer==0.10.12
 + lxml==6.0.0
 + markdown-it-py==4.0.0
 + mcp==1.13.0
 + mdurl==0.1.2
 + mistral-common==1.8.3
 + msgspec==0.19.0
 + numba==0.61.2
 - numpy==2.3.2
 + numpy==2.2.6
 + nvidia-cudnn-frontend==1.14.0
 - nvidia-ml-py==13.580.65
 + nvidia-ml-py==12.575.51
 - nvidia-nvshmem-cu12==3.3.20
 + nvidia-nvshmem-cu12==3.3.9
 + openai==1.99.9
 + openai-harmony==0.0.4
 + opencv-python-headless==4.12.0.88
 + outlines-core==0.2.10
 + partial-json-parser==0.2.1.1.post6
 + prometheus-fastapi-instrumentator==7.1.0
 + pybase64==1.4.2
 + pycountry==24.6.1
 + pydantic-extra-types==2.10.5
 + pydantic-settings==2.10.1
 + pynvml==12.0.0
 + python-multipart==0.0.20
 - pytorch-triton==3.4.0+gitf7888497
 + pytorch-triton==3.4.0+git11ec6354
 + ray==2.48.0
 + rich==14.1.0
 + rich-toolkit==0.15.0
 + rignore==0.6.4
 + setproctitle==1.3.6
 - setuptools==80.9.0
 + setuptools==79.0.1
 + shellingham==1.5.4
 + soundfile==0.13.1
 + soxr==0.5.0.post1
 + sse-starlette==3.0.2
 + structlog==25.4.0
 + tenacity==9.1.2
 + termcolor==3.1.0
 - torch==2.9.0.dev20250817+cu128
 + torch==2.9.0.dev20250804+cu128
 + torchaudio==2.8.0.dev20250804+cu128
 + torchvision==0.24.0.dev20250804+cu128
 + typer==0.16.0
 + vllm==0.10.1+gptoss
 + xgrammar==0.1.21
Waiting for vLLM server... (1)
Waiting for vLLM server... (2)
Waiting for vLLM server... (3)
Waiting for vLLM server... (4)
Waiting for vLLM server... (5)
Waiting for vLLM server... (6)
Waiting for vLLM server... (7)
Waiting for vLLM server... (8)
Waiting for vLLM server... (9)
Waiting for vLLM server... (10)
Waiting for vLLM server... (11)
Waiting for vLLM server... (12)
Waiting for vLLM server... (13)
Waiting for vLLM server... (14)
Waiting for vLLM server... (15)
Waiting for vLLM server... (16)
Waiting for vLLM server... (17)
Waiting for vLLM server... (18)
Waiting for vLLM server... (19)
Waiting for vLLM server... (20)
Waiting for vLLM server... (21)
Waiting for vLLM server... (22)
Waiting for vLLM server... (23)
Waiting for vLLM server... (24)
Waiting for vLLM server... (25)
Waiting for vLLM server... (26)
Waiting for vLLM server... (27)
Waiting for vLLM server... (28)
Waiting for vLLM server... (29)
Waiting for vLLM server... (30)
Waiting for vLLM server... (31)
Waiting for vLLM server... (32)
Waiting for vLLM server... (33)
Waiting for vLLM server... (34)
Waiting for vLLM server... (35)
Waiting for vLLM server... (36)
Waiting for vLLM server... (37)
Waiting for vLLM server... (38)
Waiting for vLLM server... (39)
Waiting for vLLM server... (40)
Waiting for vLLM server... (41)
Waiting for vLLM server... (42)
Waiting for vLLM server... (43)
Waiting for vLLM server... (44)
Waiting for vLLM server... (45)
Waiting for vLLM server... (46)
Waiting for vLLM server... (47)
Waiting for vLLM server... (48)
Waiting for vLLM server... (49)
Waiting for vLLM server... (50)
Waiting for vLLM server... (51)
Waiting for vLLM server... (52)
Waiting for vLLM server... (53)
Waiting for vLLM server... (54)
INFO 08-17 17:42:27 [__init__.py:241] Automatically detected platform cuda.
Waiting for vLLM server... (55)
Waiting for vLLM server... (56)
Waiting for vLLM server... (57)
Waiting for vLLM server... (58)
Waiting for vLLM server... (59)
Waiting for vLLM server... (60)
Waiting for vLLM server... (61)
Waiting for vLLM server... (62)
Waiting for vLLM server... (63)
Waiting for vLLM server... (64)
Waiting for vLLM server... (65)
Waiting for vLLM server... (66)
Waiting for vLLM server... (67)
Waiting for vLLM server... (68)
Waiting for vLLM server... (69)
Waiting for vLLM server... (70)
Waiting for vLLM server... (71)
Waiting for vLLM server... (72)
Waiting for vLLM server... (73)
Waiting for vLLM server... (74)
Waiting for vLLM server... (75)
Waiting for vLLM server... (76)
Waiting for vLLM server... (77)
Waiting for vLLM server... (78)
Waiting for vLLM server... (79)
Waiting for vLLM server... (80)
Waiting for vLLM server... (81)
Waiting for vLLM server... (82)
Waiting for vLLM server... (83)
Waiting for vLLM server... (84)
Waiting for vLLM server... (85)
[1;36m(APIServer pid=2212597)[0;0m INFO 08-17 17:43:28 [api_server.py:1787] vLLM API server version 0.10.2.dev2+gf5635d62e.d20250807
[1;36m(APIServer pid=2212597)[0;0m INFO 08-17 17:43:28 [utils.py:326] non-default args: {'model_tag': 'openai/gpt-oss-20b', 'model': 'openai/gpt-oss-20b', 'max_model_len': 4096, 'tensor_parallel_size': 8}
Waiting for vLLM server... (86)
Waiting for vLLM server... (87)
Waiting for vLLM server... (88)
Waiting for vLLM server... (89)
Waiting for vLLM server... (90)
Waiting for vLLM server... (91)
Waiting for vLLM server... (92)
Waiting for vLLM server... (93)
Waiting for vLLM server... (94)
Waiting for vLLM server... (95)
Waiting for vLLM server... (96)
Waiting for vLLM server... (97)
Waiting for vLLM server... (98)
Waiting for vLLM server... (99)
Waiting for vLLM server... (100)
Waiting for vLLM server... (101)
Waiting for vLLM server... (102)
Waiting for vLLM server... (103)
Waiting for vLLM server... (104)
Waiting for vLLM server... (105)
Waiting for vLLM server... (106)
Waiting for vLLM server... (107)
Waiting for vLLM server... (108)
Waiting for vLLM server... (109)
Waiting for vLLM server... (110)
Waiting for vLLM server... (111)
Waiting for vLLM server... (112)
Waiting for vLLM server... (113)
Waiting for vLLM server... (114)
Waiting for vLLM server... (115)
Waiting for vLLM server... (116)
Waiting for vLLM server... (117)
Waiting for vLLM server... (118)
Waiting for vLLM server... (119)
Waiting for vLLM server... (120)
ERROR: vLLM server did not become ready after waiting. Exiting.
[1;36m(APIServer pid=2212597)[0;0m INFO 08-17 17:45:18 [config.py:726] Resolved architecture: GptOssForCausalLM
[1;36m(APIServer pid=2212597)[0;0m Parse safetensors files:   0%|          | 0/3 [00:00<?, ?it/s]Parse safetensors files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 40.86it/s]
[1;36m(APIServer pid=2212597)[0;0m INFO 08-17 17:45:18 [config.py:1759] Using max model len 4096
[1;36m(APIServer pid=2212597)[0;0m WARNING 08-17 17:45:22 [config.py:1198] mxfp4 quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[1;36m(APIServer pid=2212597)[0;0m INFO 08-17 17:45:26 [config.py:2588] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(APIServer pid=2212597)[0;0m INFO 08-17 17:45:26 [config.py:244] Overriding cuda graph sizes to [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512, 528, 544, 560, 576, 592, 608, 624, 640, 656, 672, 688, 704, 720, 736, 752, 768, 784, 800, 816, 832, 848, 864, 880, 896, 912, 928, 944, 960, 976, 992, 1008, 1024]
INFO 08-17 17:46:56 [__init__.py:241] Automatically detected platform cuda.
[1;36m(EngineCore_0 pid=2215727)[0;0m INFO 08-17 17:47:45 [core.py:654] Waiting for init message from front-end.
[1;36m(EngineCore_0 pid=2215727)[0;0m INFO 08-17 17:47:46 [core.py:73] Initializing a V1 LLM engine (v0.10.2.dev2+gf5635d62e.d20250807) with config: model='openai/gpt-oss-20b', speculative_config=None, tokenizer='openai/gpt-oss-20b', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=8, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=mxfp4, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend='openai'), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=openai/gpt-oss-20b, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[1024,1008,992,976,960,944,928,912,896,880,864,848,832,816,800,784,768,752,736,720,704,688,672,656,640,624,608,592,576,560,544,528,512,496,480,464,448,432,416,400,384,368,352,336,320,304,288,272,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"max_capture_size":1024,"local_cache_dir":null}
[1;36m(EngineCore_0 pid=2215727)[0;0m 
[1;36m(EngineCore_0 pid=2215727)[0;0m              LL          LL          MMM       MMM 
[1;36m(EngineCore_0 pid=2215727)[0;0m              LL          LL          MMMM     MMMM
[1;36m(EngineCore_0 pid=2215727)[0;0m          V   LL          LL          MM MM   MM MM
[1;36m(EngineCore_0 pid=2215727)[0;0m vvvv  VVVV   LL          LL          MM  MM MM  MM
[1;36m(EngineCore_0 pid=2215727)[0;0m vvvv VVVV    LL          LL          MM   MMM   MM
[1;36m(EngineCore_0 pid=2215727)[0;0m  vvv VVVV    LL          LL          MM    M    MM
[1;36m(EngineCore_0 pid=2215727)[0;0m   vvVVVV     LL          LL          MM         MM
[1;36m(EngineCore_0 pid=2215727)[0;0m     VVVV     LLLLLLLLLL  LLLLLLLLL   M           M
[1;36m(EngineCore_0 pid=2215727)[0;0m 
[1;36m(EngineCore_0 pid=2215727)[0;0m WARNING 08-17 17:47:46 [multiproc_worker_utils.py:273] Reducing Torch parallelism from 112 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
[1;36m(EngineCore_0 pid=2215727)[0;0m INFO 08-17 17:47:46 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3, 4, 5, 6, 7], buffer_handle=(8, 16777216, 10, 'psm_45b6eb71'), local_subscribe_addr='ipc:///tmp/583ce3da-d1e0-4a28-ae2e-46143b4e1f5e', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 08-17 17:49:19 [__init__.py:241] Automatically detected platform cuda.
INFO 08-17 17:49:20 [__init__.py:241] Automatically detected platform cuda.
INFO 08-17 17:49:21 [__init__.py:241] Automatically detected platform cuda.
INFO 08-17 17:49:21 [__init__.py:241] Automatically detected platform cuda.
INFO 08-17 17:49:21 [__init__.py:241] Automatically detected platform cuda.
INFO 08-17 17:49:21 [__init__.py:241] Automatically detected platform cuda.
INFO 08-17 17:49:21 [__init__.py:241] Automatically detected platform cuda.
INFO 08-17 17:49:21 [__init__.py:241] Automatically detected platform cuda.
W0817 17:50:17.252000 2217106 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0817 17:50:17.252000 2217106 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0817 17:50:19.042000 2217109 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0817 17:50:19.042000 2217109 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0817 17:50:19.571000 2217104 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0817 17:50:19.571000 2217104 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0817 17:50:19.629000 2217105 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0817 17:50:19.629000 2217105 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0817 17:50:19.660000 2217110 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0817 17:50:19.660000 2217110 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0817 17:50:20.348000 2217111 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0817 17:50:20.348000 2217111 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0817 17:50:20.534000 2217107 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0817 17:50:20.534000 2217107 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0817 17:50:20.600000 2217108 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0817 17:50:20.600000 2217108 /home/kitf/.cache/uv/envs/consistency-lens/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1;36m(VllmWorker TP6 pid=2217110)[0;0m INFO 08-17 17:50:47 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_657b41fe'), local_subscribe_addr='ipc:///tmp/472bb803-40c5-4866-b6a4-c4a43751551d', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker TP0 pid=2217104)[0;0m INFO 08-17 17:50:47 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_7a5e31c7'), local_subscribe_addr='ipc:///tmp/41700619-7353-4c63-96b7-0cecb2d3dad6', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker TP3 pid=2217107)[0;0m INFO 08-17 17:50:47 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_0a708b71'), local_subscribe_addr='ipc:///tmp/721ab184-b573-46cd-b0fb-5e3d2b1515f5', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker TP2 pid=2217106)[0;0m INFO 08-17 17:50:47 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_d6174379'), local_subscribe_addr='ipc:///tmp/f0959653-6583-4310-ac10-cd3bd8347e73', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker TP1 pid=2217105)[0;0m INFO 08-17 17:50:47 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a2ef19a0'), local_subscribe_addr='ipc:///tmp/763ea204-d6c3-4e44-bdb0-9711baeeb7e3', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker TP4 pid=2217108)[0;0m INFO 08-17 17:50:47 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_adfcbf00'), local_subscribe_addr='ipc:///tmp/827cdf2d-f228-42e9-a6a5-379afc7a418b', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker TP5 pid=2217109)[0;0m INFO 08-17 17:50:47 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_6f8e8bc6'), local_subscribe_addr='ipc:///tmp/864edab4-5ece-4c6f-8a64-aca5c1b17796', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(VllmWorker TP7 pid=2217111)[0;0m INFO 08-17 17:50:47 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_c3141eaa'), local_subscribe_addr='ipc:///tmp/ec2c8389-6dfa-46c5-bc7e-ccbb38cb9db5', remote_subscribe_addr=None, remote_addr_ipv6=False)
[W817 17:50:51.604120389 ProcessGroupNCCL.cpp:915] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W817 17:50:51.604440665 ProcessGroupNCCL.cpp:915] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W817 17:50:51.609804867 ProcessGroupNCCL.cpp:915] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W817 17:50:51.614904445 ProcessGroupNCCL.cpp:915] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W817 17:50:51.620311806 ProcessGroupNCCL.cpp:915] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W817 17:50:51.667126810 ProcessGroupNCCL.cpp:915] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W817 17:50:51.706207750 ProcessGroupNCCL.cpp:915] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[W817 17:50:51.710297242 ProcessGroupNCCL.cpp:915] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1;36m(VllmWorker TP5 pid=2217109)[0;0m INFO 08-17 17:50:51 [__init__.py:1381] Found nccl from library libnccl.so.2
[1;36m(VllmWorker TP2 pid=2217106)[0;0m INFO 08-17 17:50:51 [__init__.py:1381] Found nccl from library libnccl.so.2
[1;36m(VllmWorker TP1 pid=2217105)[0;0m INFO 08-17 17:50:51 [__init__.py:1381] Found nccl from library libnccl.so.2
[1;36m(VllmWorker TP5 pid=2217109)[0;0m INFO 08-17 17:50:51 [pynccl.py:70] vLLM is using nccl==2.27.5
[1;36m(VllmWorker TP2 pid=2217106)[0;0m INFO 08-17 17:50:51 [pynccl.py:70] vLLM is using nccl==2.27.5
[1;36m(VllmWorker TP1 pid=2217105)[0;0m INFO 08-17 17:50:51 [pynccl.py:70] vLLM is using nccl==2.27.5
[1;36m(VllmWorker TP7 pid=2217111)[0;0m INFO 08-17 17:50:51 [__init__.py:1381] Found nccl from library libnccl.so.2
[1;36m(VllmWorker TP6 pid=2217110)[0;0m INFO 08-17 17:50:51 [__init__.py:1381] Found nccl from library libnccl.so.2
[1;36m(VllmWorker TP4 pid=2217108)[0;0m INFO 08-17 17:50:51 [__init__.py:1381] Found nccl from library libnccl.so.2
[1;36m(VllmWorker TP7 pid=2217111)[0;0m INFO 08-17 17:50:51 [pynccl.py:70] vLLM is using nccl==2.27.5
[1;36m(VllmWorker TP6 pid=2217110)[0;0m INFO 08-17 17:50:51 [pynccl.py:70] vLLM is using nccl==2.27.5
[1;36m(VllmWorker TP4 pid=2217108)[0;0m INFO 08-17 17:50:51 [pynccl.py:70] vLLM is using nccl==2.27.5
[1;36m(VllmWorker TP3 pid=2217107)[0;0m INFO 08-17 17:50:51 [__init__.py:1381] Found nccl from library libnccl.so.2
[1;36m(VllmWorker TP0 pid=2217104)[0;0m INFO 08-17 17:50:51 [__init__.py:1381] Found nccl from library libnccl.so.2
[1;36m(VllmWorker TP3 pid=2217107)[0;0m INFO 08-17 17:50:51 [pynccl.py:70] vLLM is using nccl==2.27.5
[1;36m(VllmWorker TP0 pid=2217104)[0;0m INFO 08-17 17:50:51 [pynccl.py:70] vLLM is using nccl==2.27.5
[1;36m(VllmWorker TP1 pid=2217105)[0;0m INFO 08-17 17:50:56 [custom_all_reduce.py:35] Skipping P2P check and trusting the driver's P2P report.
[1;36m(VllmWorker TP3 pid=2217107)[0;0m INFO 08-17 17:50:56 [custom_all_reduce.py:35] Skipping P2P check and trusting the driver's P2P report.
[1;36m(VllmWorker TP5 pid=2217109)[0;0m INFO 08-17 17:50:56 [custom_all_reduce.py:35] Skipping P2P check and trusting the driver's P2P report.
[1;36m(VllmWorker TP2 pid=2217106)[0;0m INFO 08-17 17:50:56 [custom_all_reduce.py:35] Skipping P2P check and trusting the driver's P2P report.
[1;36m(VllmWorker TP6 pid=2217110)[0;0m INFO 08-17 17:50:56 [custom_all_reduce.py:35] Skipping P2P check and trusting the driver's P2P report.
[1;36m(VllmWorker TP0 pid=2217104)[0;0m INFO 08-17 17:50:56 [custom_all_reduce.py:35] Skipping P2P check and trusting the driver's P2P report.
[1;36m(VllmWorker TP4 pid=2217108)[0;0m INFO 08-17 17:50:56 [custom_all_reduce.py:35] Skipping P2P check and trusting the driver's P2P report.
[1;36m(VllmWorker TP7 pid=2217111)[0;0m INFO 08-17 17:50:56 [custom_all_reduce.py:35] Skipping P2P check and trusting the driver's P2P report.
[1;36m(VllmWorker TP0 pid=2217104)[0;0m INFO 08-17 17:50:56 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3, 4, 5, 6, 7], buffer_handle=(7, 4194304, 6, 'psm_14d4d1fb'), local_subscribe_addr='ipc:///tmp/80c44022-a8b1-44fc-b165-a1f26953cb2c', remote_subscribe_addr=None, remote_addr_ipv6=False)
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[1;36m(VllmWorker TP4 pid=2217108)[0;0m INFO 08-17 17:50:56 [parallel_state.py:1102] rank 4 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 4, EP rank 4
[1;36m(VllmWorker TP0 pid=2217104)[0;0m INFO 08-17 17:50:56 [parallel_state.py:1102] rank 0 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(VllmWorker TP1 pid=2217105)[0;0m INFO 08-17 17:50:56 [parallel_state.py:1102] rank 1 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1
[1;36m(VllmWorker TP2 pid=2217106)[0;0m INFO 08-17 17:50:56 [parallel_state.py:1102] rank 2 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 2, EP rank 2
[1;36m(VllmWorker TP5 pid=2217109)[0;0m INFO 08-17 17:50:56 [parallel_state.py:1102] rank 5 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 5, EP rank 5
[1;36m(VllmWorker TP6 pid=2217110)[0;0m INFO 08-17 17:50:56 [parallel_state.py:1102] rank 6 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 6, EP rank 6
[1;36m(VllmWorker TP7 pid=2217111)[0;0m INFO 08-17 17:50:56 [parallel_state.py:1102] rank 7 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 7, EP rank 7
[1;36m(VllmWorker TP3 pid=2217107)[0;0m INFO 08-17 17:50:56 [parallel_state.py:1102] rank 3 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 3, EP rank 3
[1;36m(VllmWorker TP0 pid=2217104)[0;0m INFO 08-17 17:50:56 [topk_topp_sampler.py:49] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker TP5 pid=2217109)[0;0m INFO 08-17 17:50:56 [topk_topp_sampler.py:49] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker TP2 pid=2217106)[0;0m INFO 08-17 17:50:56 [topk_topp_sampler.py:49] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker TP4 pid=2217108)[0;0m INFO 08-17 17:50:56 [topk_topp_sampler.py:49] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker TP1 pid=2217105)[0;0m INFO 08-17 17:50:56 [topk_topp_sampler.py:49] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker TP7 pid=2217111)[0;0m INFO 08-17 17:50:56 [topk_topp_sampler.py:49] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker TP6 pid=2217110)[0;0m INFO 08-17 17:50:56 [topk_topp_sampler.py:49] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker TP5 pid=2217109)[0;0m INFO 08-17 17:50:56 [gpu_model_runner.py:1913] Starting to load model openai/gpt-oss-20b...
[1;36m(VllmWorker TP3 pid=2217107)[0;0m INFO 08-17 17:50:56 [topk_topp_sampler.py:49] Using FlashInfer for top-p & top-k sampling.
[1;36m(VllmWorker TP2 pid=2217106)[0;0m INFO 08-17 17:50:56 [gpu_model_runner.py:1913] Starting to load model openai/gpt-oss-20b...
[1;36m(VllmWorker TP0 pid=2217104)[0;0m INFO 08-17 17:50:56 [gpu_model_runner.py:1913] Starting to load model openai/gpt-oss-20b...
[1;36m(VllmWorker TP1 pid=2217105)[0;0m INFO 08-17 17:50:56 [gpu_model_runner.py:1913] Starting to load model openai/gpt-oss-20b...
[1;36m(VllmWorker TP7 pid=2217111)[0;0m INFO 08-17 17:50:56 [gpu_model_runner.py:1913] Starting to load model openai/gpt-oss-20b...
[1;36m(VllmWorker TP4 pid=2217108)[0;0m INFO 08-17 17:50:56 [gpu_model_runner.py:1913] Starting to load model openai/gpt-oss-20b...
[1;36m(VllmWorker TP6 pid=2217110)[0;0m INFO 08-17 17:50:56 [gpu_model_runner.py:1913] Starting to load model openai/gpt-oss-20b...
[1;36m(VllmWorker TP3 pid=2217107)[0;0m INFO 08-17 17:50:56 [gpu_model_runner.py:1913] Starting to load model openai/gpt-oss-20b...
[1;36m(VllmWorker TP4 pid=2217108)[0;0m INFO 08-17 17:50:57 [gpu_model_runner.py:1945] Loading model from scratch...
[1;36m(VllmWorker TP0 pid=2217104)[0;0m INFO 08-17 17:50:57 [gpu_model_runner.py:1945] Loading model from scratch...
[1;36m(VllmWorker TP5 pid=2217109)[0;0m INFO 08-17 17:50:57 [gpu_model_runner.py:1945] Loading model from scratch...
[1;36m(VllmWorker TP2 pid=2217106)[0;0m INFO 08-17 17:50:57 [gpu_model_runner.py:1945] Loading model from scratch...
[1;36m(VllmWorker TP1 pid=2217105)[0;0m INFO 08-17 17:50:57 [gpu_model_runner.py:1945] Loading model from scratch...
[1;36m(VllmWorker TP6 pid=2217110)[0;0m INFO 08-17 17:50:57 [gpu_model_runner.py:1945] Loading model from scratch...
[1;36m(VllmWorker TP4 pid=2217108)[0;0m INFO 08-17 17:50:57 [cuda.py:323] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker TP0 pid=2217104)[0;0m INFO 08-17 17:50:57 [cuda.py:323] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker TP5 pid=2217109)[0;0m INFO 08-17 17:50:57 [cuda.py:323] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker TP1 pid=2217105)[0;0m INFO 08-17 17:50:57 [cuda.py:323] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker TP2 pid=2217106)[0;0m INFO 08-17 17:50:57 [cuda.py:323] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker TP3 pid=2217107)[0;0m INFO 08-17 17:50:57 [gpu_model_runner.py:1945] Loading model from scratch...
[1;36m(VllmWorker TP7 pid=2217111)[0;0m INFO 08-17 17:50:57 [gpu_model_runner.py:1945] Loading model from scratch...
[1;36m(VllmWorker TP6 pid=2217110)[0;0m INFO 08-17 17:50:57 [cuda.py:323] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker TP3 pid=2217107)[0;0m INFO 08-17 17:50:57 [cuda.py:323] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker TP7 pid=2217111)[0;0m INFO 08-17 17:50:57 [cuda.py:323] Using Flash Attention backend on V1 engine.
[1;36m(VllmWorker TP4 pid=2217108)[0;0m INFO 08-17 17:50:59 [weight_utils.py:296] Using model weights format ['*.safetensors']
[1;36m(VllmWorker TP1 pid=2217105)[0;0m INFO 08-17 17:50:59 [weight_utils.py:296] Using model weights format ['*.safetensors']
[1;36m(VllmWorker TP0 pid=2217104)[0;0m INFO 08-17 17:50:59 [weight_utils.py:296] Using model weights format ['*.safetensors']
[1;36m(VllmWorker TP2 pid=2217106)[0;0m INFO 08-17 17:50:59 [weight_utils.py:296] Using model weights format ['*.safetensors']
[1;36m(VllmWorker TP5 pid=2217109)[0;0m INFO 08-17 17:50:59 [weight_utils.py:296] Using model weights format ['*.safetensors']
[1;36m(VllmWorker TP6 pid=2217110)[0;0m INFO 08-17 17:50:59 [weight_utils.py:296] Using model weights format ['*.safetensors']
[1;36m(VllmWorker TP7 pid=2217111)[0;0m INFO 08-17 17:50:59 [weight_utils.py:296] Using model weights format ['*.safetensors']
[1;36m(VllmWorker TP3 pid=2217107)[0;0m INFO 08-17 17:50:59 [weight_utils.py:296] Using model weights format ['*.safetensors']
[1;36m(VllmWorker TP4 pid=2217108)[0;0m INFO 08-17 17:51:12 [weight_utils.py:312] Time spent downloading weights for openai/gpt-oss-20b: 13.852386 seconds
[1;36m(VllmWorker TP0 pid=2217104)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(VllmWorker TP0 pid=2217104)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:01<00:03,  1.90s/it]
[1;36m(VllmWorker TP0 pid=2217104)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:05<00:03,  3.02s/it]
[1;36m(VllmWorker TP0 pid=2217104)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:09<00:00,  3.22s/it]
[1;36m(VllmWorker TP0 pid=2217104)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:09<00:00,  3.05s/it]
[1;36m(VllmWorker TP0 pid=2217104)[0;0m 
[1;36m(VllmWorker TP1 pid=2217105)[0;0m INFO 08-17 17:51:22 [default_loader.py:262] Loading weights took 9.46 seconds
[1;36m(VllmWorker TP5 pid=2217109)[0;0m INFO 08-17 17:51:22 [default_loader.py:262] Loading weights took 8.83 seconds
[1;36m(VllmWorker TP3 pid=2217107)[0;0m INFO 08-17 17:51:22 [default_loader.py:262] Loading weights took 8.98 seconds
[1;36m(VllmWorker TP0 pid=2217104)[0;0m INFO 08-17 17:51:22 [default_loader.py:262] Loading weights took 9.29 seconds
[1;36m(VllmWorker TP4 pid=2217108)[0;0m INFO 08-17 17:51:22 [default_loader.py:262] Loading weights took 10.01 seconds
[1;36m(VllmWorker TP7 pid=2217111)[0;0m INFO 08-17 17:51:22 [default_loader.py:262] Loading weights took 9.80 seconds
[1;36m(VllmWorker TP2 pid=2217106)[0;0m INFO 08-17 17:51:22 [default_loader.py:262] Loading weights took 8.54 seconds
[1;36m(VllmWorker TP6 pid=2217110)[0;0m INFO 08-17 17:51:22 [default_loader.py:262] Loading weights took 9.15 seconds
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559] WorkerProc failed to start.
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559] Traceback (most recent call last):
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/executor/multiproc_executor.py", line 533, in worker_main
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]     worker = WorkerProc(*args, **kwargs)
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/executor/multiproc_executor.py", line 402, in __init__
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]     self.worker.load_model()
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 211, in load_model
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1946, in load_model
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]     self.model = model_loader.load_model(
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 50, in load_model
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]     process_weights_after_loading(model, model_config, target_device)
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 112, in process_weights_after_loading
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]     quant_method.process_weights_after_loading(module)
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/model_executor/layers/quantization/mxfp4.py", line 298, in process_weights_after_loading
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]     from triton_kernels.matmul_ogs import FlexCtx, PrecisionConfig
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/triton_kernels/matmul_ogs.py", line 11, in <module>
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]     from triton_kernels import target_info
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/triton_kernels/target_info.py", line 5, in <module>
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559]     from triton.language.target_info import (
[1;36m(VllmWorker TP4 pid=2217108)[0;0m ERROR 08-17 17:51:23 [multiproc_executor.py:559] ModuleNotFoundError: No module named 'triton.language.target_info'
[1;36m(VllmWorker TP4 pid=2217108)[0;0m INFO 08-17 17:51:23 [multiproc_executor.py:520] Parent process exited, terminating worker
[1;36m(VllmWorker TP0 pid=2217104)[0;0m INFO 08-17 17:51:23 [multiproc_executor.py:520] Parent process exited, terminating worker
[1;36m(VllmWorker TP5 pid=2217109)[0;0m INFO 08-17 17:51:23 [multiproc_executor.py:520] Parent process exited, terminating worker
[1;36m(VllmWorker TP2 pid=2217106)[0;0m INFO 08-17 17:51:24 [multiproc_executor.py:520] Parent process exited, terminating worker
[1;36m(VllmWorker TP1 pid=2217105)[0;0m INFO 08-17 17:51:24 [multiproc_executor.py:520] Parent process exited, terminating worker
[1;36m(VllmWorker TP6 pid=2217110)[0;0m INFO 08-17 17:51:24 [multiproc_executor.py:520] Parent process exited, terminating worker
[1;36m(VllmWorker TP3 pid=2217107)[0;0m INFO 08-17 17:51:24 [multiproc_executor.py:520] Parent process exited, terminating worker
[1;36m(VllmWorker TP7 pid=2217111)[0;0m INFO 08-17 17:51:24 [multiproc_executor.py:520] Parent process exited, terminating worker
[rank0]:[W817 17:51:24.068670640 ProcessGroupNCCL.cpp:1522] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718] EngineCore failed to start.
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718] Traceback (most recent call last):
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718]   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 709, in run_engine_core
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718]   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 510, in __init__
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718]     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718]   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 82, in __init__
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718]   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718]     self._init_executor()
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718]   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/executor/multiproc_executor.py", line 96, in _init_executor
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718]     self.workers = WorkerProc.wait_for_ready(unready_workers)
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718]   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/executor/multiproc_executor.py", line 472, in wait_for_ready
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718]     raise e from None
[1;36m(EngineCore_0 pid=2215727)[0;0m ERROR 08-17 17:51:27 [core.py:718] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
[1;36m(EngineCore_0 pid=2215727)[0;0m Process EngineCore_0:
[1;36m(EngineCore_0 pid=2215727)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_0 pid=2215727)[0;0m   File "/home/kitf/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_0 pid=2215727)[0;0m     self.run()
[1;36m(EngineCore_0 pid=2215727)[0;0m   File "/home/kitf/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_0 pid=2215727)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_0 pid=2215727)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 722, in run_engine_core
[1;36m(EngineCore_0 pid=2215727)[0;0m     raise e
[1;36m(EngineCore_0 pid=2215727)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 709, in run_engine_core
[1;36m(EngineCore_0 pid=2215727)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_0 pid=2215727)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=2215727)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 510, in __init__
[1;36m(EngineCore_0 pid=2215727)[0;0m     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_0 pid=2215727)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 82, in __init__
[1;36m(EngineCore_0 pid=2215727)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_0 pid=2215727)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=2215727)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_0 pid=2215727)[0;0m     self._init_executor()
[1;36m(EngineCore_0 pid=2215727)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/executor/multiproc_executor.py", line 96, in _init_executor
[1;36m(EngineCore_0 pid=2215727)[0;0m     self.workers = WorkerProc.wait_for_ready(unready_workers)
[1;36m(EngineCore_0 pid=2215727)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=2215727)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/executor/multiproc_executor.py", line 472, in wait_for_ready
[1;36m(EngineCore_0 pid=2215727)[0;0m     raise e from None
[1;36m(EngineCore_0 pid=2215727)[0;0m Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.
[1;36m(APIServer pid=2212597)[0;0m Traceback (most recent call last):
[1;36m(APIServer pid=2212597)[0;0m   File "/home/kitf/.cache/uv/envs/consistency-lens/bin/vllm", line 10, in <module>
[1;36m(APIServer pid=2212597)[0;0m     sys.exit(main())
[1;36m(APIServer pid=2212597)[0;0m              ^^^^^^
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/entrypoints/cli/main.py", line 54, in main
[1;36m(APIServer pid=2212597)[0;0m     args.dispatch_function(args)
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/entrypoints/cli/serve.py", line 50, in cmd
[1;36m(APIServer pid=2212597)[0;0m     uvloop.run(run_server(args))
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/uvloop/__init__.py", line 109, in run
[1;36m(APIServer pid=2212597)[0;0m     return __asyncio.run(
[1;36m(APIServer pid=2212597)[0;0m            ^^^^^^^^^^^^^^
[1;36m(APIServer pid=2212597)[0;0m   File "/home/kitf/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/asyncio/runners.py", line 195, in run
[1;36m(APIServer pid=2212597)[0;0m     return runner.run(main)
[1;36m(APIServer pid=2212597)[0;0m            ^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=2212597)[0;0m   File "/home/kitf/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/asyncio/runners.py", line 118, in run
[1;36m(APIServer pid=2212597)[0;0m     return self._loop.run_until_complete(task)
[1;36m(APIServer pid=2212597)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=2212597)[0;0m   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/uvloop/__init__.py", line 61, in wrapper
[1;36m(APIServer pid=2212597)[0;0m     return await main
[1;36m(APIServer pid=2212597)[0;0m            ^^^^^^^^^^
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/api_server.py", line 1827, in run_server
[1;36m(APIServer pid=2212597)[0;0m     await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/api_server.py", line 1847, in run_server_worker
[1;36m(APIServer pid=2212597)[0;0m     async with build_async_engine_client(
[1;36m(APIServer pid=2212597)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=2212597)[0;0m   File "/home/kitf/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/contextlib.py", line 210, in __aenter__
[1;36m(APIServer pid=2212597)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=2212597)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/api_server.py", line 167, in build_async_engine_client
[1;36m(APIServer pid=2212597)[0;0m     async with build_async_engine_client_from_engine_args(
[1;36m(APIServer pid=2212597)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=2212597)[0;0m   File "/home/kitf/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/contextlib.py", line 210, in __aenter__
[1;36m(APIServer pid=2212597)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=2212597)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/api_server.py", line 209, in build_async_engine_client_from_engine_args
[1;36m(APIServer pid=2212597)[0;0m     async_llm = AsyncLLM.from_vllm_config(
[1;36m(APIServer pid=2212597)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/utils/__init__.py", line 1520, in inner
[1;36m(APIServer pid=2212597)[0;0m     return fn(*args, **kwargs)
[1;36m(APIServer pid=2212597)[0;0m            ^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/engine/async_llm.py", line 173, in from_vllm_config
[1;36m(APIServer pid=2212597)[0;0m     return cls(
[1;36m(APIServer pid=2212597)[0;0m            ^^^^
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/engine/async_llm.py", line 119, in __init__
[1;36m(APIServer pid=2212597)[0;0m     self.engine_core = EngineCoreClient.make_async_mp_client(
[1;36m(APIServer pid=2212597)[0;0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/engine/core_client.py", line 101, in make_async_mp_client
[1;36m(APIServer pid=2212597)[0;0m     return AsyncMPClient(*client_args)
[1;36m(APIServer pid=2212597)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/engine/core_client.py", line 733, in __init__
[1;36m(APIServer pid=2212597)[0;0m     super().__init__(
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/engine/core_client.py", line 421, in __init__
[1;36m(APIServer pid=2212597)[0;0m     with launch_core_engines(vllm_config, executor_class,
[1;36m(APIServer pid=2212597)[0;0m          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=2212597)[0;0m   File "/home/kitf/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/contextlib.py", line 144, in __exit__
[1;36m(APIServer pid=2212597)[0;0m     next(self.gen)
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/engine/utils.py", line 697, in launch_core_engines
[1;36m(APIServer pid=2212597)[0;0m     wait_for_engine_startup(
[1;36m(APIServer pid=2212597)[0;0m   File "/workspace/kitf/talkative-probes/talkative_autoencoder/.venv/lib/python3.12/site-packages/vllm/v1/engine/utils.py", line 750, in wait_for_engine_startup
[1;36m(APIServer pid=2212597)[0;0m     raise RuntimeError("Engine core initialization failed. "
[1;36m(APIServer pid=2212597)[0;0m RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
/home/kitf/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/multiprocessing/resource_tracker.py:279: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
